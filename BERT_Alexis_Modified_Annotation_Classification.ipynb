{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Alexis_Modified_Annotation_Classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Nihl0cmh_e",
        "colab_type": "text"
      },
      "source": [
        "Following  [this]( https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784) blog for sentence classification using a pretrained BERT model, with multiclass, instead of binary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3vg4xdi-h3h",
        "colab_type": "code",
        "outputId": "28644e33-c8fa-4e30-fee6-8a294f9ea6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_oXjrFC_-BG",
        "colab_type": "code",
        "outputId": "2ace10b3-388f-44cf-a9ca-30b36f675aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "% cd drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkPd7Kk6Ainl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from random import randrange\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxBm6BTgATeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('PTSD_data_Colton_Alexis.csv', nrows = 865)# limiting the number of rows to only the text that has already been annotated by Alexis\n",
        "#,delimiter='\\t',encoding='utf-8', nrows=10000)#, encoding =\"ISO-8859-1\" , names=DATASET_COLUMNS, nrows=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "torgXT4W8z2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = pd.read_csv('PTSD_data_Colton_Alexis.csv',  skiprows=3)\n",
        "raw_annotations = pd.read_csv(\"PTSD_data_conversation_annotation.csv\", skiprows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvvhUlPDAVQX",
        "colab_type": "code",
        "outputId": "9d5b2702-f791-4fd8-d16c-343277079317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>character</th>\n",
              "      <th>text</th>\n",
              "      <th>Keywords / Significant sentences</th>\n",
              "      <th>A1</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>E1</th>\n",
              "      <th>E2</th>\n",
              "      <th>E3</th>\n",
              "      <th>E4</th>\n",
              "      <th>E5</th>\n",
              "      <th>E6</th>\n",
              "      <th>F1</th>\n",
              "      <th>G1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>CLIENT</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>THERAPIST</td>\n",
              "      <td>Those darn women.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>CLIENT</td>\n",
              "      <td>Damn women. Our boss is she's just a shut the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>THERAPIST</td>\n",
              "      <td>It's not that comfortable.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>CLIENT</td>\n",
              "      <td>What's that?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id  character  ...   F1   G1\n",
              "0   PTSD_file_1     CLIENT  ...  0.0  0.0\n",
              "1   PTSD_file_1  THERAPIST  ...  0.0  0.0\n",
              "2   PTSD_file_1     CLIENT  ...  0.0  0.0\n",
              "3   PTSD_file_1  THERAPIST  ...  0.0  0.0\n",
              "4   PTSD_file_1     CLIENT  ...  0.0  0.0\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEgPbi9M9xAe",
        "colab_type": "code",
        "outputId": "e025ac7a-2192-4682-feca-5c5cfa712fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Session_id</th>\n",
              "      <th>Scorer</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>G</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Session_id  Scorer    A    B    C    D    E    G\n",
              "0  PTSD_file_1  Alexis  1.0  0.0  1.0  1.0  0.0  0.0\n",
              "1  PTSD_file_2  Alexis  1.0  1.0  1.0  1.0  1.0  0.0\n",
              "2  PTSD_file_3  Alexis  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  PTSD_file_4  Alexis  0.0  1.0  1.0  1.0  1.0  0.0\n",
              "4  PTSD_file_5  Alexis  1.0  0.0  0.0  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsufUCJa93_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_text_combined = raw_data.groupby(\"transcript_id\")[\"text\"].agg(lambda col: ' '.join(col))\n",
        "text_transcript_combined = raw_text_combined.to_frame()\n",
        "text_transcript_combined.reset_index(level=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz4zvfSc97vH",
        "colab_type": "code",
        "outputId": "a0463fcb-8018-4ea4-c10a-407561083c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "text_transcript_combined.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_10</td>\n",
              "      <td>The arch. How was time?  Good, good, thanks. Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_11</td>\n",
              "      <td>(yawning) Hi. Hi.  I don’t know why I can’t ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_12</td>\n",
              "      <td>Hi. Come on in. Morning. Morning. Is it less c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_13</td>\n",
              "      <td>(inaudible response)  Thanks for not having (i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id                                               text\n",
              "0   PTSD_file_1  Remind me never to go to a work meeting with a...\n",
              "1  PTSD_file_10  The arch. How was time?  Good, good, thanks. Y...\n",
              "2  PTSD_file_11  (yawning) Hi. Hi.  I don’t know why I can’t ge...\n",
              "3  PTSD_file_12  Hi. Come on in. Morning. Morning. Is it less c...\n",
              "4  PTSD_file_13  (inaudible response)  Thanks for not having (i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cg1N7Or-BMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_annotations[\"label\"] = (raw_annotations[\"A\"]+raw_annotations[\"B\"]+raw_annotations[\"C\"]+raw_annotations[\"D\"]+raw_annotations[\"E\"]+raw_annotations[\"G\"])/6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZDrRi0Z-OPN",
        "colab_type": "code",
        "outputId": "c4d4d6c3-c825-42ed-d05b-ac4292bcbca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Session_id</th>\n",
              "      <th>Scorer</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>G</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Session_id  Scorer    A    B    C    D    E    G     label\n",
              "0  PTSD_file_1  Alexis  1.0  0.0  1.0  1.0  0.0  0.0  0.500000\n",
              "1  PTSD_file_2  Alexis  1.0  1.0  1.0  1.0  1.0  0.0  0.833333\n",
              "2  PTSD_file_3  Alexis  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "3  PTSD_file_4  Alexis  0.0  1.0  1.0  1.0  1.0  0.0  0.666667\n",
              "4  PTSD_file_5  Alexis  1.0  0.0  0.0  0.0  0.0  0.0  0.166667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DM2ZuQa-X_C",
        "colab_type": "code",
        "outputId": "031db5d8-df57-4d1a-9bf7-c263acd4f313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_annotations = raw_annotations.round({\"label\":0})[[\"Session_id\",\"label\"]]\n",
        "final_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Session_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Session_id  label\n",
              "0  PTSD_file_1    0.0\n",
              "1  PTSD_file_2    1.0\n",
              "2  PTSD_file_3    0.0\n",
              "3  PTSD_file_4    1.0\n",
              "4  PTSD_file_5    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXO1DejQ-eub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_annotations = final_annotations.rename(columns = {\"Session_id\": \"transcript_id\"}) \n",
        "final_annotations.label = final_annotations.label.fillna(0)\n",
        "final_annotations.label = final_annotations.label.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTHyT8H-esN",
        "colab_type": "code",
        "outputId": "25306e2d-04f3-4ec4-c64a-4f08176dc733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id  label\n",
              "0   PTSD_file_1      0\n",
              "1   PTSD_file_2      1\n",
              "2   PTSD_file_3      0\n",
              "3   PTSD_file_4      1\n",
              "4   PTSD_file_5      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie9DIL_D-ONF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_dataset = pd.merge(text_transcript_combined, final_annotations, on='transcript_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa_fQ8Uu-733",
        "colab_type": "code",
        "outputId": "947301fb-d7fe-4c9f-f14b-1b5e0fa75e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_10</td>\n",
              "      <td>The arch. How was time?  Good, good, thanks. Y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_11</td>\n",
              "      <td>(yawning) Hi. Hi.  I don’t know why I can’t ge...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_12</td>\n",
              "      <td>Hi. Come on in. Morning. Morning. Is it less c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_13</td>\n",
              "      <td>(inaudible response)  Thanks for not having (i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id                                               text  label\n",
              "0   PTSD_file_1  Remind me never to go to a work meeting with a...      0\n",
              "1  PTSD_file_10  The arch. How was time?  Good, good, thanks. Y...      1\n",
              "2  PTSD_file_11  (yawning) Hi. Hi.  I don’t know why I can’t ge...      1\n",
              "3  PTSD_file_12  Hi. Come on in. Morning. Morning. Is it less c...      0\n",
              "4  PTSD_file_13  (inaudible response)  Thanks for not having (i...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBypQTEvMMhF",
        "colab_type": "code",
        "outputId": "4d07612c-ec6a-4ceb-d8ea-093bfd8ac7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "final_dataset['label'].hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9a51b77278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ms3ImLa_VPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'label':final_dataset.label, 'text':final_dataset.text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSGcOF4k_X_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into training and transfer\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "# split data into training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlIJ9PAxIe3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.values.tolist()\n",
        "X_test = X_test.values.tolist()\n",
        "\n",
        "y_train = pd.get_dummies(y_train).values.tolist()\n",
        "y_test = pd.get_dummies(y_test).values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i4V2DKqnAds",
        "colab_type": "text"
      },
      "source": [
        "# **Loading BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRiflTqeBs25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "package_dir = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
        "sys.path.append(package_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2Js9GxFChQ",
        "colab_type": "code",
        "outputId": "04e4d3fe-d91f-401e-d36d-34b8ad79c400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.202)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.6.8)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.202 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.202)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.6.16)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.202->boto3->pytorch-pretrained-bert) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.202->boto3->pytorch-pretrained-bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.202->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_qHFNX5FEUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "#import pytorch_pretrained_bert\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from pytorch_pretrained_bert import BertConfig\n",
        "from pytorch_pretrained_bert.modeling import BertModel, BertForMaskedLM\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 5)\n",
        "\n",
        "warnings.filterwarnings(action='once')\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3doMeMFITS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w5K5SN0AwHc",
        "colab_type": "text"
      },
      "source": [
        "# **Preparing data for training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ6t5TOCnKCc",
        "colab_type": "text"
      },
      "source": [
        "Now we create a class to preprocess data that involves tokenizing, truncating and padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8xKgazJ29_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "class text_dataset(Dataset):\n",
        "    def __init__(self,x_y_list, transform=None):\n",
        "        \n",
        "        self.x_y_list = x_y_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n",
        "        \n",
        "        if len(tokenized_review) > max_seq_length:\n",
        "            tokenized_review = tokenized_review[:max_seq_length]\n",
        "            \n",
        "        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(ids_review))\n",
        "        \n",
        "        ids_review += padding\n",
        "        \n",
        "        assert len(ids_review) == max_seq_length\n",
        "        \n",
        "        #print(\"Hello\")\n",
        "        ids_review = torch.tensor(ids_review).long()\n",
        "        \n",
        "        sentiment = self.x_y_list[1][index] # color        \n",
        "        list_of_labels = [torch.from_numpy(np.array(sentiment)).long()]\n",
        "        \n",
        "        \n",
        "        return ids_review, list_of_labels[0]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x_y_list[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQrQTCRrnZXt",
        "colab_type": "text"
      },
      "source": [
        "Preparing and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA3U816YksO_",
        "colab_type": "code",
        "outputId": "22e3e205-f40c-4414-f877-b42ca764e589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_lists = [X_train, y_train]\n",
        "test_lists = [X_test, y_test]\n",
        "\n",
        "training_dataset = text_dataset(x_y_list = train_lists )\n",
        "\n",
        "test_dataset = text_dataset(x_y_list = test_lists )\n",
        "\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "                   }\n",
        "dataset_sizes = {'train':len(train_lists[0]),\n",
        "                'val':len(test_lists[0])}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUL5uFF5c_05",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2xL96andIXZ",
        "colab_type": "text"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVep1AogIndK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias\n",
        "        \n",
        "\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller\n",
        "            than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, num_labels=2):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBh7tlgI1it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "num_labels = 2\n",
        "model = BertForSequenceClassification(num_labels)\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])\n",
        "\n",
        "#logits = model(tokens_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7B4rLMnFR4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    print('starting')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 100\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            sentiment_corrects = 0\n",
        "            \n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, sentiment in dataloaders_dict[phase]:\n",
        "                #print(\"ok till here\")\n",
        "                #inputs = inputs\n",
        "                #print(len(inputs),type(inputs),inputs)\n",
        "                #inputs = torch.from_numpy(np.array(inputs)).to(device) \n",
        "                inputs = inputs.to(device) \n",
        "\n",
        "                sentiment = sentiment.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        " \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #print(inputs)\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    outputs = F.softmax(outputs,dim = 1)\n",
        "                    \n",
        "                    loss = criterion(outputs, torch.max(sentiment.float(), 1)[1])\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                \n",
        "                sentiment_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(sentiment, 1)[1])\n",
        "\n",
        "                \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            \n",
        "            sentiment_acc = sentiment_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
        "            print('{} sentiment_acc: {:.4f}'.format(\n",
        "                phase, sentiment_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print('saving with loss of {}'.format(epoch_loss),\n",
        "                      'improved over previous {}'.format(best_loss))\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDoE-BzSH41N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrlast = .001\n",
        "lrmain = .00001\n",
        "optim1 = optim.Adam(\n",
        "    [\n",
        "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
        "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
        "       \n",
        "   ])\n",
        "\n",
        "#optim1 = optim.Adam(model.parameters(), lr=0.001)#,momentum=.9)\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKcj7f5J0KM",
        "colab_type": "code",
        "outputId": "deb2e915-2f81-4ec2-b88f-065e601b2060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.to(device)\n",
        "model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting\n",
            "Epoch 0/9\n",
            "----------\n",
            "train total loss: 0.6914 \n",
            "train sentiment_acc: 0.5526\n",
            "val total loss: 0.3713 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.37133076786994934 improved over previous 100\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train total loss: 0.5336 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3205 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.3205055594444275 improved over previous 0.37133076786994934\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train total loss: 0.5260 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3196 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.31958839297294617 improved over previous 0.3205055594444275\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train total loss: 0.5253 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3190 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.31898385286331177 improved over previous 0.31958839297294617\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train total loss: 0.5248 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3186 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.3185860216617584 improved over previous 0.31898385286331177\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train total loss: 0.5239 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3186 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.31855422258377075 improved over previous 0.3185860216617584\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train total loss: 0.5254 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3185 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.3185262382030487 improved over previous 0.31855422258377075\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train total loss: 0.5251 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3185 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.3185017704963684 improved over previous 0.3185262382030487\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train total loss: 0.5244 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3185 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.3185000717639923 improved over previous 0.3185017704963684\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train total loss: 0.5247 \n",
            "train sentiment_acc: 0.7895\n",
            "val total loss: 0.3185 \n",
            "val sentiment_acc: 1.0000\n",
            "saving with loss of 0.31849879026412964 improved over previous 0.3185000717639923\n",
            "\n",
            "Training complete in 1m 23s\n",
            "Best val Acc: 0.318499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67OKez2ecjDg",
        "colab_type": "text"
      },
      "source": [
        "# **TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sP_L6Hz_ybT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#final_test = pd.read_csv('test.tsv',delimiter='\\t',encoding='utf-8')\n",
        "#X_final_test = final_test['Phrase']\n",
        "#X_final_test = X_final_test.values.tolist()\n",
        "X_final_test = ['I am depressed','You are very kind', 'I have distressing dreams']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7TJU0QQeYxL",
        "colab_type": "text"
      },
      "source": [
        "Define a function to preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvT8bf2OtU_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "reviews=[]\n",
        "def test_dataset(Dataset):\n",
        "    for i in range(0,len(Dataset)):\n",
        "      tokenized_review = tokenizer.tokenize(Dataset[i])\n",
        "\n",
        "      if len(tokenized_review) > max_seq_length:\n",
        "          tokenized_review = tokenized_review[:max_seq_length]\n",
        "\n",
        "      ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "      padding = [0] * (max_seq_length - len(ids_review))\n",
        "\n",
        "      ids_review += padding\n",
        "\n",
        "      assert len(ids_review) == max_seq_length\n",
        "\n",
        "      #print(\"Hello\")\n",
        "      reviews.append(ids_review)\n",
        "\n",
        "    #sentiment = self.x_y_list[1][index] # color        \n",
        "    #list_of_labels = [torch.from_numpy(np.array(sentiment))]\n",
        "\n",
        "\n",
        "    return reviews#, list_of_labels[0]\n",
        "\n",
        "#def __len__(self):\n",
        " #   return len(self.x_list)\n",
        "X_final_test = test_dataset(X_final_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc5BXD-eun9",
        "colab_type": "text"
      },
      "source": [
        "Define the model and the configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_REsL6c4Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "num_labels = 2\n",
        "model = BertForSequenceClassification(num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBCAQx5qe2Tn",
        "colab_type": "text"
      },
      "source": [
        "Load the previously saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfE191JybN1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('bert_model_test.pth'))\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.eval()\n",
        "l = len(X_final_test)\n",
        "test_preds = np.zeros((l,num_labels))\n",
        "tests =  torch.utils.data.TensorDataset(torch.tensor(X_final_test))\n",
        "test_loader = torch.utils.data.DataLoader(tests, batch_size=l, shuffle=False)\n",
        "\n",
        "for i,(x_batch,)  in enumerate(test_loader):\n",
        "    t_preds = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "    test_preds[i:i+l]=t_preds[:,0:num_labels].detach().cpu().squeeze().numpy()\n",
        "#test_preds = t_preds[:,0:23].detach().cpu().squeeze.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUYt2GnCfBUH",
        "colab_type": "text"
      },
      "source": [
        "Run our test list through the model and write the results to a file called test_preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxACSX5KhFb0",
        "colab_type": "code",
        "outputId": "339fbe66-28d2-47e9-8234-59e296d4a367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "t_p = pd.DataFrame(test_preds)\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "test_preds1 = t_p.apply(lambda x:softmax(x), axis=1)\n",
        "test_preds1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.955855</td>\n",
              "      <td>0.044145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.925170</td>\n",
              "      <td>0.074830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.926858</td>\n",
              "      <td>0.073142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1\n",
              "0  0.955855  0.044145\n",
              "1  0.925170  0.074830\n",
              "2  0.926858  0.073142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YANaL0t0foAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(test_preds1).to_csv(\"test_preds1.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQHzO45lUCdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duviFKynUUTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}